{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and load the required libraries and modules \n",
    "import random\n",
    "random.seed(732)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# setting display perference options in jupyter notbook \n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading required dataset\n",
    "df = pd.read_csv(\"dataset_diabetes/diabetic_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare missing values \n",
    "df = df.replace('?', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to show persentage of missing values in the dataset\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns\n",
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all have alot of missing values, so these features will be excluded \n",
    "df = df.drop(['weight','payer_code','medical_specialty'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude any missing or errorness values\n",
    "excluded_indecies = set(df[(df['diag_1'].isna()) & (df['diag_2'].isna()) & (df['diag_3'].isna())].index) \n",
    "excluded_indecies = excluded_indecies.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "excluded_indecies = excluded_indecies.union(set(df[df['discharge_disposition_id'] == 11].index))\n",
    "new_indecies = list(set(df.index) - set(excluded_indecies))\n",
    "df = df.iloc[new_indecies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant value columns\n",
    "df = df.drop(['citoglipton', 'examide'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering : Creating new features :{service_utilization,n_medication_changes,n_medications}\n",
    "# 1- service_utilization\n",
    "#summerize into one column \n",
    "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
    "# 2- n_medication_changes \n",
    "# count changes\n",
    "meds = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "df['n_medication_changes'] = 0\n",
    "for i in meds:\n",
    "    temp_col = str(i) + '_'\n",
    "    df[temp_col] = df[i].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "    df['n_medication_changes'] = df['n_medication_changes'] + df[temp_col]\n",
    "    del df[temp_col]\n",
    "# 3- n_medications\n",
    "# count medications\n",
    "for i in meds:\n",
    "    df[i] = df[i].replace('No', 0)\n",
    "    df[i] = df[i].replace('Steady', 1)\n",
    "    df[i] = df[i].replace('Up', 1)\n",
    "    df[i] = df[i].replace('Down', 1) \n",
    "df['n_medications'] = 0\n",
    "for i in meds:\n",
    "    df['n_medications'] = df['n_medications'] + df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping\n",
    "# 4 categories\n",
    "\n",
    "df['admission_type'] = df['admission_type_id']\n",
    "df['admission_type'] = df['admission_type'].replace(1,'Emergency')\n",
    "df['admission_type'] = df['admission_type'].replace(2,'Emergency')\n",
    "df['admission_type'] = df['admission_type'].replace(3,'Elective')\n",
    "df['admission_type'] = df['admission_type'].replace(4,'Newborn')\n",
    "df['admission_type'] = df['admission_type'].replace(5,'N/A')\n",
    "df['admission_type'] = df['admission_type'].replace(6,'N/A')\n",
    "df['admission_type'] = df['admission_type'].replace(7,'Emergency')\n",
    "df['admission_type'] = df['admission_type'].replace(8,'N/A')\n",
    "\n",
    "# 6 categories\n",
    "df['admission_source'] = df['admission_source_id']\n",
    "df['admission_source'] = df['admission_source'].replace(1,'Referral')\n",
    "df['admission_source'] = df['admission_source'].replace(2,'Referral')\n",
    "df['admission_source'] = df['admission_source'].replace(3,'Referral')\n",
    "df['admission_source'] = df['admission_source'].replace(4,'Transfer')\n",
    "df['admission_source'] = df['admission_source'].replace(5,'Transfer')\n",
    "df['admission_source'] = df['admission_source'].replace(6,'Transfer')\n",
    "df['admission_source'] = df['admission_source'].replace(7,'ER')\n",
    "df['admission_source'] = df['admission_source'].replace(8,'Law_Enforcement')\n",
    "df['admission_source'] = df['admission_source'].replace(9,'N/A')\n",
    "df['admission_source'] = df['admission_source'].replace(10,'Transfer')\n",
    "df['admission_source'] = df['admission_source'].replace(11,'Birth')\n",
    "df['admission_source'] = df['admission_source'].replace(13,'Birth')\n",
    "df['admission_source'] = df['admission_source'].replace(14,'Birth')\n",
    "df['admission_source'] = df['admission_source'].replace(15,'N/A')\n",
    "df['admission_source'] = df['admission_source'].replace(17,'N/A')\n",
    "df['admission_source'] = df['admission_source'].replace(20,'N/A')\n",
    "df['admission_source'] = df['admission_source'].replace(21,'N/A')\n",
    "df['admission_source'] = df['admission_source'].replace(22,'Transfer')\n",
    "df['admission_source'] = df['admission_source'].replace(25,'Transfer')\n",
    "\n",
    "# 7 categories\n",
    "df['discharge_disposition'] = df['discharge_disposition_id']\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(1,\"Home\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(2,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(3,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(4,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(5,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(6,\"Home\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(7,\"AMA\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(8,\"Home\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(9,\"Home\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(10,\"Outpatient\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(12,\"Outpatient\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(13,\"Home\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(14,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(15,\"Outpatient\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(16,\"Outpatient\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(17,\"Outpatient\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(18,\"N/A\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(19,\"Expired\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(20,\"Expired\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(22,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(23,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(24,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(25,\"N/A\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(26,\"N/A\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(27,\"Transferred\")\n",
    "df['discharge_disposition'] = df['discharge_disposition'].replace(28,\"To_Psychiatric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disease categories for codes are in the paper\n",
    "df['diag_1'] = df['diag_1'].convert_objects(convert_numeric=True)\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(390, 459),'Circulatory' , df['diag_1'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(460, 519),'Respiratory' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(520, 579),'Digestive' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(250.00, 250.99),'Diabetes' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(800, 999),'Injury' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(710, 739),'Musculoskeletal' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(580, 629),'Genitourinary' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(140, 239),'Neoplasms' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 785,'Circulatory' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 786,'Respiratory' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 787,'Digestive' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 788,'Genitourinary' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(740, 759),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(630, 709),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(240, 249),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(251, 389),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(1, 139),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(780, 782),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].between(790, 799),'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 784,'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 783,'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1']== 789,'other' , df['diag_1_label'])\n",
    "df['diag_1_label'] = np.where(df['diag_1'].isna(),'other' , df['diag_1_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Coding the columns\n",
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1) \n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)\n",
    "\n",
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)\n",
    "\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('None', -99) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform age category to average age\n",
    "df['age'] = df.age.map({\"[0-10)\":5,\n",
    "                        \"[10-20)\":15,\n",
    "                        \"[20-30)\":25,\n",
    "                        \"[30-40)\":35,\n",
    "                        \"[40-50)\":45,\n",
    "                        \"[50-60)\":55,\n",
    "                        \"[60-70)\":65,\n",
    "                        \"[70-80)\":75,\n",
    "                        \"[80-90)\":85,\n",
    "                        \"[90-100)\":95})\n",
    "df['age'] = df['age'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one encounter per patient to avoid bias\n",
    "df = df.sort_values('encounter_id').drop_duplicates(subset=['patient_nbr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation\n",
    "num_col = ['time_in_hospital',\n",
    " 'number_inpatient',\n",
    " 'number_diagnoses',\n",
    " 'num_medications',\n",
    " 'number_outpatient',\n",
    " 'service_utilization',\n",
    " 'n_medication_changes',\n",
    " 'number_emergency',\n",
    " 'num_lab_procedures',\n",
    " 'num_procedures',\n",
    " 'age',\n",
    " 'n_medications']\n",
    "skewed_col = pd.DataFrame()\n",
    "skewed_col_names = []\n",
    "skewed_col_values = []\n",
    "skewed_col_values_ = []\n",
    "for i in num_col:\n",
    "    skewness = df[i].skew()   \n",
    "    if (abs(skewness) >2): \n",
    "        skewed_col_values.append(skewness)\n",
    "        df = df[df[i] >= 0]\n",
    "        df[i + \"_log1p\"] = np.log1p(df[i])\n",
    "        skewness = df[i + \"_log1p\"].skew()  \n",
    "        skewed_col_values_.append(skewness)\n",
    "skewed_col['column'] = skewed_col_names\n",
    "skewed_col['skew'] = skewed_col_values\n",
    "skewed_col['skew after logp1'] = skewed_col_values_\n",
    "# print skewness table\n",
    "skewed_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "df_pd = pd.get_dummies(df, columns=['race', 'gender', 'admission_type', 'discharge_disposition',\n",
    "                                      'admission_source', 'max_glu_serum', 'A1Cresult', 'diag_1_label'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for Standrization using z-score\n",
    "def z_score(data):\n",
    "    return ((data - np.mean(data, axis = 0)) / np.std(data, axis = 0))\n",
    "df_pd[col_numeric] = z_score(df_pd[col_numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverSampling using SMOTE\n",
    "X = df_pd.loc[:, df_pd.columns != 'readmitted']\n",
    "y = df_pd['readmitted']\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from collections import Counter\n",
    "print('Before SMOTE {}'.format(Counter(y)))\n",
    "sm = SMOTE(random_state=0)\n",
    "os_data_X, os_data_y = sm.fit_sample(X, y)\n",
    "print('After SMOTE {}'.format(Counter(os_data_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using RFE by training a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "rf = RandomForestClassifier(n_estimators = 10, max_depth=25)\n",
    "# create the RFE model for the svm classifier \n",
    "# and select attributes\n",
    "rfe = RFE(rf, 15)\n",
    "X_new = rfe.fit_transform(os_data_X, os_data_y)\n",
    "# print summaries for the selection of attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of top most features based on importance\n",
    "feature_names = pd.DataFrame(X).columns\n",
    "feature_imports = rfe.estimator_.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"])\n",
    "# plot the feature importances\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Features importance - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, os_data_y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier model with GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid_param = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "                          'penalty': ['l1', 'l2'],\n",
    "                          'solver' :[\"lbfgs\",'newton-cg']\n",
    "                          }\n",
    "logreg=LogisticRegression()\n",
    "gd_sr = GridSearchCV(estimator=logreg,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters) \n",
    "best_result = gd_sr.best_score_  \n",
    "print(best_result)  \n",
    "print(gd_sr.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knearest neighbors Classifier model with GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "grid_param = {'n_neighbors': [1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
    "                              15]}\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, grid_param, cv=5, scoring='accuracy', n_jobs= -1)\n",
    "grid.fit(X_train, y_train)\n",
    "# print results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-37274050f613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Random forest Classifier with grid search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier()\n",
    "grid_param = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [15,25, 50],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10, 100, 200, 1000]\n",
    "}\n",
    "grid = GridSearchCV(clf, grid_param, cv=5, scoring='accuracy', n_jobs= -1)\n",
    "grid.fit(X_train, y_train)\n",
    "# print results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost Classifier with grid search \n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "grid_param = {\n",
    "    'learning_rate'=[0.01,0.1],\n",
    "    'max_depth': [15,25, 50],\n",
    "    'n_estimators': [10, 100, 200, 1000]\n",
    "}\n",
    "grid = GridSearchCV(model, grid_param, cv=5, scoring='accuracy', n_jobs= -1)\n",
    "grid.fit(X_train, y_train)\n",
    "# print results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier with grid search \n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma=1,C=1)\n",
    "grid_param = {\n",
    "    'gamma'=[0.001,0.01,1],\n",
    "    'C'=[0.001,0.01,1],\n",
    "    'kernel'=['linear','poly', 'rbf']\n",
    "}\n",
    "grid = GridSearchCV(model, grid_param, cv=5, scoring='accuracy', n_jobs= -1)\n",
    "grid.fit(X_train, y_train)\n",
    "# print results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree visualization of LOS \n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(model, out_file='tree_limited.dot', \n",
    "                feature_names=pd.DataFrame(X).columns[pd.DataFrame(X_new).columns], max_depth=2,\n",
    "                class_names=[\"<5 days\",\"5 to 8 days\",\">8 days\"],\n",
    "                rounded = True, proportion = False, precision = 2,filled=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
